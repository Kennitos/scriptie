{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":78,"outputs":[{"output_type":"stream","text":"['train.csv', 'sample_submission.csv', 'test.csv', 'data_description.txt']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Loading the training set"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\ntrain.describe(include='all')","execution_count":79,"outputs":[{"output_type":"execute_result","execution_count":79,"data":{"text/plain":"                 Id   MSSubClass      ...       SaleCondition      SalePrice\ncount   1460.000000  1460.000000      ...                1460    1460.000000\nunique          NaN          NaN      ...                   6            NaN\ntop             NaN          NaN      ...              Normal            NaN\nfreq            NaN          NaN      ...                1198            NaN\nmean     730.500000    56.897260      ...                 NaN  180921.195890\nstd      421.610009    42.300571      ...                 NaN   79442.502883\nmin        1.000000    20.000000      ...                 NaN   34900.000000\n25%      365.750000    20.000000      ...                 NaN  129975.000000\n50%      730.500000    50.000000      ...                 NaN  163000.000000\n75%     1095.250000    70.000000      ...                 NaN  214000.000000\nmax     1460.000000   190.000000      ...                 NaN  755000.000000\n\n[11 rows x 81 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>Street</th>\n      <th>Alley</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>Utilities</th>\n      <th>LotConfig</th>\n      <th>LandSlope</th>\n      <th>Neighborhood</th>\n      <th>Condition1</th>\n      <th>Condition2</th>\n      <th>BldgType</th>\n      <th>HouseStyle</th>\n      <th>OverallQual</th>\n      <th>OverallCond</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>RoofStyle</th>\n      <th>RoofMatl</th>\n      <th>Exterior1st</th>\n      <th>Exterior2nd</th>\n      <th>MasVnrType</th>\n      <th>MasVnrArea</th>\n      <th>ExterQual</th>\n      <th>ExterCond</th>\n      <th>Foundation</th>\n      <th>BsmtQual</th>\n      <th>BsmtCond</th>\n      <th>BsmtExposure</th>\n      <th>BsmtFinType1</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinType2</th>\n      <th>BsmtFinSF2</th>\n      <th>BsmtUnfSF</th>\n      <th>TotalBsmtSF</th>\n      <th>Heating</th>\n      <th>...</th>\n      <th>CentralAir</th>\n      <th>Electrical</th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>LowQualFinSF</th>\n      <th>GrLivArea</th>\n      <th>BsmtFullBath</th>\n      <th>BsmtHalfBath</th>\n      <th>FullBath</th>\n      <th>HalfBath</th>\n      <th>BedroomAbvGr</th>\n      <th>KitchenAbvGr</th>\n      <th>KitchenQual</th>\n      <th>TotRmsAbvGrd</th>\n      <th>Functional</th>\n      <th>Fireplaces</th>\n      <th>FireplaceQu</th>\n      <th>GarageType</th>\n      <th>GarageYrBlt</th>\n      <th>GarageFinish</th>\n      <th>GarageCars</th>\n      <th>GarageArea</th>\n      <th>GarageQual</th>\n      <th>GarageCond</th>\n      <th>PavedDrive</th>\n      <th>WoodDeckSF</th>\n      <th>OpenPorchSF</th>\n      <th>EnclosedPorch</th>\n      <th>3SsnPorch</th>\n      <th>ScreenPorch</th>\n      <th>PoolArea</th>\n      <th>PoolQC</th>\n      <th>Fence</th>\n      <th>MiscFeature</th>\n      <th>MiscVal</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460</td>\n      <td>1201.000000</td>\n      <td>1460.000000</td>\n      <td>1460</td>\n      <td>91</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1452</td>\n      <td>1452.000000</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1423</td>\n      <td>1423</td>\n      <td>1422</td>\n      <td>1423</td>\n      <td>1460.000000</td>\n      <td>1422</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460</td>\n      <td>...</td>\n      <td>1460</td>\n      <td>1459</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460</td>\n      <td>1460.000000</td>\n      <td>1460</td>\n      <td>1460.000000</td>\n      <td>770</td>\n      <td>1379</td>\n      <td>1379.000000</td>\n      <td>1379</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1379</td>\n      <td>1379</td>\n      <td>1460</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>7</td>\n      <td>281</td>\n      <td>54</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460.000000</td>\n      <td>1460</td>\n      <td>1460</td>\n      <td>1460.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>4</td>\n      <td>2</td>\n      <td>5</td>\n      <td>3</td>\n      <td>25</td>\n      <td>9</td>\n      <td>8</td>\n      <td>5</td>\n      <td>8</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>8</td>\n      <td>15</td>\n      <td>16</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>5</td>\n      <td>6</td>\n      <td>4</td>\n      <td>4</td>\n      <td>4</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6</td>\n      <td>...</td>\n      <td>2</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>7</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>6</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5</td>\n      <td>5</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>4</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>9</td>\n      <td>6</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>RL</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Pave</td>\n      <td>Grvl</td>\n      <td>Reg</td>\n      <td>Lvl</td>\n      <td>AllPub</td>\n      <td>Inside</td>\n      <td>Gtl</td>\n      <td>NAmes</td>\n      <td>Norm</td>\n      <td>Norm</td>\n      <td>1Fam</td>\n      <td>1Story</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gable</td>\n      <td>CompShg</td>\n      <td>VinylSd</td>\n      <td>VinylSd</td>\n      <td>None</td>\n      <td>NaN</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>PConc</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>No</td>\n      <td>Unf</td>\n      <td>NaN</td>\n      <td>Unf</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>GasA</td>\n      <td>...</td>\n      <td>Y</td>\n      <td>SBrkr</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>TA</td>\n      <td>NaN</td>\n      <td>Typ</td>\n      <td>NaN</td>\n      <td>Gd</td>\n      <td>Attchd</td>\n      <td>NaN</td>\n      <td>Unf</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>TA</td>\n      <td>TA</td>\n      <td>Y</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Gd</td>\n      <td>MnPrv</td>\n      <td>Shed</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>WD</td>\n      <td>Normal</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1151</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1454</td>\n      <td>50</td>\n      <td>925</td>\n      <td>1311</td>\n      <td>1459</td>\n      <td>1052</td>\n      <td>1382</td>\n      <td>225</td>\n      <td>1260</td>\n      <td>1445</td>\n      <td>1220</td>\n      <td>726</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1141</td>\n      <td>1434</td>\n      <td>515</td>\n      <td>504</td>\n      <td>864</td>\n      <td>NaN</td>\n      <td>906</td>\n      <td>1282</td>\n      <td>647</td>\n      <td>649</td>\n      <td>1311</td>\n      <td>953</td>\n      <td>430</td>\n      <td>NaN</td>\n      <td>1256</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1428</td>\n      <td>...</td>\n      <td>1365</td>\n      <td>1334</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>735</td>\n      <td>NaN</td>\n      <td>1360</td>\n      <td>NaN</td>\n      <td>380</td>\n      <td>870</td>\n      <td>NaN</td>\n      <td>605</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1311</td>\n      <td>1326</td>\n      <td>1340</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>157</td>\n      <td>49</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1267</td>\n      <td>1198</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>730.500000</td>\n      <td>56.897260</td>\n      <td>NaN</td>\n      <td>70.049958</td>\n      <td>10516.828082</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.099315</td>\n      <td>5.575342</td>\n      <td>1971.267808</td>\n      <td>1984.865753</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>103.685262</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>443.639726</td>\n      <td>NaN</td>\n      <td>46.549315</td>\n      <td>567.240411</td>\n      <td>1057.429452</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1162.626712</td>\n      <td>346.992466</td>\n      <td>5.844521</td>\n      <td>1515.463699</td>\n      <td>0.425342</td>\n      <td>0.057534</td>\n      <td>1.565068</td>\n      <td>0.382877</td>\n      <td>2.866438</td>\n      <td>1.046575</td>\n      <td>NaN</td>\n      <td>6.517808</td>\n      <td>NaN</td>\n      <td>0.613014</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1978.506164</td>\n      <td>NaN</td>\n      <td>1.767123</td>\n      <td>472.980137</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>94.244521</td>\n      <td>46.660274</td>\n      <td>21.954110</td>\n      <td>3.409589</td>\n      <td>15.060959</td>\n      <td>2.758904</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>43.489041</td>\n      <td>6.321918</td>\n      <td>2007.815753</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>180921.195890</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>421.610009</td>\n      <td>42.300571</td>\n      <td>NaN</td>\n      <td>24.284752</td>\n      <td>9981.264932</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.382997</td>\n      <td>1.112799</td>\n      <td>30.202904</td>\n      <td>20.645407</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>181.066207</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>456.098091</td>\n      <td>NaN</td>\n      <td>161.319273</td>\n      <td>441.866955</td>\n      <td>438.705324</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>386.587738</td>\n      <td>436.528436</td>\n      <td>48.623081</td>\n      <td>525.480383</td>\n      <td>0.518911</td>\n      <td>0.238753</td>\n      <td>0.550916</td>\n      <td>0.502885</td>\n      <td>0.815778</td>\n      <td>0.220338</td>\n      <td>NaN</td>\n      <td>1.625393</td>\n      <td>NaN</td>\n      <td>0.644666</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>24.689725</td>\n      <td>NaN</td>\n      <td>0.747315</td>\n      <td>213.804841</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>125.338794</td>\n      <td>66.256028</td>\n      <td>61.119149</td>\n      <td>29.317331</td>\n      <td>55.757415</td>\n      <td>40.177307</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>496.123024</td>\n      <td>2.703626</td>\n      <td>1.328095</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>79442.502883</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>20.000000</td>\n      <td>NaN</td>\n      <td>21.000000</td>\n      <td>1300.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1872.000000</td>\n      <td>1950.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>334.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>334.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>2.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1900.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>2006.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>34900.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>365.750000</td>\n      <td>20.000000</td>\n      <td>NaN</td>\n      <td>59.000000</td>\n      <td>7553.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.000000</td>\n      <td>5.000000</td>\n      <td>1954.000000</td>\n      <td>1967.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>223.000000</td>\n      <td>795.750000</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>882.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1129.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>5.000000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1961.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>334.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>5.000000</td>\n      <td>2007.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>129975.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>730.500000</td>\n      <td>50.000000</td>\n      <td>NaN</td>\n      <td>69.000000</td>\n      <td>9478.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6.000000</td>\n      <td>5.000000</td>\n      <td>1973.000000</td>\n      <td>1994.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>383.500000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>477.500000</td>\n      <td>991.500000</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1087.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1464.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>6.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1980.000000</td>\n      <td>NaN</td>\n      <td>2.000000</td>\n      <td>480.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>25.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>6.000000</td>\n      <td>2008.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>163000.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1095.250000</td>\n      <td>70.000000</td>\n      <td>NaN</td>\n      <td>80.000000</td>\n      <td>11601.500000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7.000000</td>\n      <td>6.000000</td>\n      <td>2000.000000</td>\n      <td>2004.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>166.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>712.250000</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>808.000000</td>\n      <td>1298.250000</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1391.250000</td>\n      <td>728.000000</td>\n      <td>0.000000</td>\n      <td>1776.750000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>7.000000</td>\n      <td>NaN</td>\n      <td>1.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2002.000000</td>\n      <td>NaN</td>\n      <td>2.000000</td>\n      <td>576.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>168.000000</td>\n      <td>68.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.000000</td>\n      <td>8.000000</td>\n      <td>2009.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>214000.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1460.000000</td>\n      <td>190.000000</td>\n      <td>NaN</td>\n      <td>313.000000</td>\n      <td>215245.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>10.000000</td>\n      <td>9.000000</td>\n      <td>2010.000000</td>\n      <td>2010.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1600.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5644.000000</td>\n      <td>NaN</td>\n      <td>1474.000000</td>\n      <td>2336.000000</td>\n      <td>6110.000000</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4692.000000</td>\n      <td>2065.000000</td>\n      <td>572.000000</td>\n      <td>5642.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>8.000000</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>14.000000</td>\n      <td>NaN</td>\n      <td>3.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2010.000000</td>\n      <td>NaN</td>\n      <td>4.000000</td>\n      <td>1418.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>857.000000</td>\n      <td>547.000000</td>\n      <td>552.000000</td>\n      <td>508.000000</td>\n      <td>480.000000</td>\n      <td>738.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>15500.000000</td>\n      <td>12.000000</td>\n      <td>2010.000000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>755000.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Removing outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Deleting outliers\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)","execution_count":80,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#We use the numpy fuction log1p which  applies log(1+x) to all elements of the column\ntrain[\"SalePrice\"] = np.log1p(train[\"SalePrice\"])","execution_count":81,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking for missing values, only for numeric variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\n#my_imputer = SimpleImputer()\n\n#numeric_columns = (train.dtypes == 'int64') | (train.dtypes == 'float64')\n#train_numeric = (train[numeric_columns.index[numeric_columns]])\n#train_non_numeric = train.drop(numeric_columns.index[numeric_columns],axis=1)\n","execution_count":82,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputed_X_train = pd.DataFrame(my_imputer.fit_transform(train_numeric))\n#imputed_X_train.columns = train_numeric.columns\n#Now there are no null values for the numeric attributes","execution_count":83,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Credits for data imputations go to\nhttps://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard"},{"metadata":{"trusted":true},"cell_type":"code","source":"ntrain = train.shape[0]\nntest = test.shape[0]\ny = train.SalePrice.values\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))\n\nall_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\nall_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\nall_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\nall_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))\n\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')\n    \nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\n\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\n\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')\n\n\nall_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n\nall_data = all_data.drop(['Utilities'], axis=1)\n\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n\nall_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n\n\n#MSSubClass=The building class\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n\n\n#Changing OverallCond into a categorical variable\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n\n\n#Year and month sold are transformed into categorical features.\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)\n\nfrom sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n# process columns, apply LabelEncoder to categorical features\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))\n\n# shape        \nprint('Shape all_data: {}'.format(all_data.shape))\n\n\n# Adding total sqfootage feature \nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n\nall_data = pd.get_dummies(all_data)\nprint(all_data.shape)\n\nX = all_data[:ntrain]\nX_test = all_data[ntrain:]\n\n\n#train = pd.concat([imputed_X_train, train_non_numeric], axis=1)\n#X = train.drop(['Id','SalePrice'],axis=1)\n\n","execution_count":84,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n  after removing the cwd from sys.path.\n","name":"stderr"},{"output_type":"stream","text":"all_data size is : (2917, 80)\nShape all_data: (2917, 79)\n(2917, 221)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting categorical features into their one-hot-encoding versions\n#X = pd.get_dummies(X)\n#print(X.columns.values)\n#y = train['SalePrice']\n#print('Shape of the X train tensor: ',X.shape)\n#print('Shape of the y train tensor: ',y.shape)\n\n\n#test = pd.read_csv('../input/test.csv')\n#X_test = test.drop('Id',axis = 1)\n#X_test = pd.get_dummies(X_test)\n#print('Shape of the X test tensor: ',X_test.shape)\n\n#We gotta eliminate those columns generated by the one-hot-encoding in the train not present in the test\n#X = X[X_test.columns]\n#print('New shape for the X train tensor: ',X.shape)\n\n#print(X.columns)\n#print(X_test.columns)\n#(X.columns == X_test.columns).all()\n\n","execution_count":85,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Normalizing features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n","execution_count":86,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n","name":"stderr"}]},{"metadata":{},"cell_type":"markdown","source":"Feature selection"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\nfrom sklearn.feature_selection import SelectFromModel\n\n#clf = ExtraTreesClassifier(n_estimators=1000, n_jobs = -1)\n#clf = clf.fit(X, y)\n\n#model = SelectFromModel(clf, prefit=True)\n#X = model.transform(X)\n#X.shape ","execution_count":87,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\nX_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size = 0.1)","execution_count":88,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom math import log10, sqrt\n\nn_estimators = 1000\nregr = RandomForestRegressor(n_estimators=n_estimators, n_jobs = -1)\nregr.fit(X_train, y_train)\n\ny_pred = (regr.predict(X_val))\n\nprint('RMSE (of the logs) for the random forest with', n_estimators, ' estimator = ' ,(sqrt(mean_squared_error(np.log(y_val),np.log(y_pred)))))","execution_count":89,"outputs":[{"output_type":"stream","text":"RMSE (of the logs) for the random forest with 1000  estimator =  9.559162748469594\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\nn_estimators_XGB = 1000\nXGB_reg = XGBRegressor(n_estimators=n_estimators_XGB, learning_rate=0.01, n_jobs=-1)\nXGB_reg.fit(X_train, y_train, \n             early_stopping_rounds=5, \n             eval_set=[(X_val, y_val)], \n             verbose=False)\n\ny_pred = (XGB_reg.predict(X_val))\nprint('RMSE for the XGBoost with', n_estimators_XGB, ' estimator = ' ,(sqrt(mean_squared_error(np.log(y_val),np.log(y_pred)))))","execution_count":90,"outputs":[{"output_type":"stream","text":"RMSE for the XGBoost with 1000  estimator =  9.569260858929924\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\n\nMLP = Sequential()\nMLP.add(Dense(512, activation = 'relu', input_shape=(X_train.shape[1],)))\nMLP.add(Dense(512, activation = 'relu'))\nMLP.add(Dense(1, activation = 'linear'))\n\nMLP.compile(optimizer = 'adam', loss = 'mean_squared_error')\n\n#MLP.fit(X_train,y_train, validation_data = (X_val,y_val), epochs = 10, batch_size = None, \n#          steps_per_epoch = 1000, validation_steps = 10)","execution_count":91,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred_MLP = np.expm1(MLP.predict(X_val))\n#print('RMSE for the MLP = ' ,(sqrt(mean_squared_error(np.log(y_val),np.log(y_pred_MLP)))))\n","execution_count":92,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prediction on the test set"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_scaled = scaler.transform(X_test)","execution_count":93,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n  \"\"\"Entry point for launching an IPython kernel.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test = np.expm1(XGB_reg.predict(X_test_scaled))","execution_count":94,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv = pd.DataFrame(data=test['Id'])\ndf_csv['SalePrice'] = y_pred_test\ndf_csv.head()","execution_count":95,"outputs":[{"output_type":"execute_result","execution_count":95,"data":{"text/plain":"     Id      SalePrice\n0  1461  119070.109375\n1  1462  162184.375000\n2  1463  184928.750000\n3  1464  184069.937500\n4  1465  191840.343750","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1461</td>\n      <td>119070.109375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1462</td>\n      <td>162184.375000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1463</td>\n      <td>184928.750000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1464</td>\n      <td>184069.937500</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1465</td>\n      <td>191840.343750</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_csv.to_csv('submission.csv',index=False)","execution_count":96,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}