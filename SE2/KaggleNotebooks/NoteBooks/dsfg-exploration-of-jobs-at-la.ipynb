{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Problem Objective:\n\n#### Help the City of Los Angeles to structure and analyze its job descriptions\n\nThe City of Los Angeles faces a big hiring challenge: 1/3 of its 50,000 workers are eligible to retire by July of 2020. The city has partnered with Kaggle to create a competition to improve the job bulletins that will fill all those open positions.\n\nThe content, tone, and format of job bulletins can influence the quality of the applicant pool. Overly-specific job requirements may discourage diversity. The Los Angeles Mayor’s Office wants to reimagine the city’s job bulletins by using text analysis to identify needed improvements.\n\nThe goal is to convert a folder full of plain-text job postings into a structured CSV file and then to use this data to: \n\n(1) identify language that can negatively bias the pool of applicants; \n\n(2) improve the diversity and quality of the applicant pool; and/or \n\n(3) make it easier to determine which promotions are available to employees in each job class."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Import python packages\nimport os\nfrom os import walk\nimport shutil\nfrom shutil import copytree, ignore_patterns\nfrom PIL import Image\nfrom wand.image import Image as Img\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom wordcloud import WordCloud, STOPWORDS\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nThanks to Paul Mooney's [Kernel](https://www.kaggle.com/paultimothymooney/explore-job-postings), let us first start by looking at some of the job postings to get an idea of how they look like."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pdf = '../input/cityofla/CityofLA/Additional data/PDFs/2014/April 2014/040414/PORT POLICE SERGEANT 3222.pdf'\nImg(filename=pdf, resolution=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pdf = '../input/cityofla/CityofLA/Additional data/PDFs/2018/December/Dec 14/CABLE TELEVISION PRODUCTION MANAGER 1801 121418.pdf'\nImg(filename=pdf, resolution=200)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like the job postings have a generic format which they adhere to like \n\n1. Job Title at the first line\n2. Job code in the next line\n3. Job open date in the next line \n4. Annual Salary in the next part\n5. Duties in the next part\n6. Requirements / Qualifications in the next part\n7. Where to apply information\n8. Application deadline information\n\nSo the aim of the contest (as well as this notebook) is to parse the application and to get some structured information out of these files. Also we will do some analysis to understand the content of the job postings.\n\nWe have also got a sample template on how the parsed file will look like. Let us have a look at it. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"sample_output_df = pd.read_csv(\"../input/cityofla/CityofLA/Additional data/sample job class export template.csv\")\nsample_output_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need to extract the contents and make it structureds like the above one. We also need to create a data dictionary like the below one for the created fields."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"data_dict_df = pd.read_csv(\"../input/cityofla/CityofLA/Additional data/kaggle_data_dictionary.csv\")\ndata_dict_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are also given the job descriptions in plain text files. Let us get the total number of files and have a look at top few lines of one of the files."},{"metadata":{"trusted":true},"cell_type":"code","source":"job_bulletins_path = \"../input/cityofla/CityofLA/Job Bulletins/\"\nprint(\"Number of Job bulletins : \",len(os.listdir(job_bulletins_path)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(job_bulletins_path + os.listdir(job_bulletins_path)[0]) as f: \n    print (f.read(1000))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Extraction\n\nIn this section, let us extract the data and create a structured table out of it.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"jobs_list = []\nfor file_name in os.listdir(job_bulletins_path):\n    with open(job_bulletins_path + file_name, encoding = \"ISO-8859-1\") as f:\n        content = f.read()\n        jobs_list.append([file_name, content])\njobs_df = pd.DataFrame(jobs_list)\njobs_df.columns = [\"FileName\", \"Content\"]\njobs_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### More to come. Stay tuned! "}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}