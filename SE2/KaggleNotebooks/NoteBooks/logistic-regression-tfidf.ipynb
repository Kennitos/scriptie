{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.linear_model import LogisticRegression # clf model\nfrom sklearn.feature_extraction.text import TfidfVectorizer \nfrom sklearn.pipeline import make_union # combine two vectors\nfrom sklearn.model_selection import cross_val_score # validate clf using training data\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['train.csv', 'sample_submission.csv', 'test.csv']\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# Load the datasets\ntrain_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create word and char Tfidf vectors\n\nword_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='word',\n    token_pattern=r'\\w{1,}',\n    ngram_range=(1, 2),\n    max_features=30000)\n\nchar_vectorizer = TfidfVectorizer(\n    sublinear_tf=True,\n    strip_accents='unicode',\n    analyzer='char',\n    ngram_range=(1, 4),\n    max_features=30000)\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine the word and char vectors\nvectorizer = make_union(word_vectorizer, char_vectorizer, n_jobs=3)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert comments to vectors (bag of words)\n\ntrain_comments = train_data['comment_text']\ntest_comments = test_data['comment_text']\n\nvectorizer.fit(train_comments)\n\ntrain_features = vectorizer.transform(train_comments)\ntest_features = vectorizer.transform(test_comments)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = []\nclass_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\nsubmission = pd.DataFrame.from_dict({'id': test_data['id']})\n\n# Train each class, validate using cross validate and predic the probability\nfor class_name in class_names:\n    train_target = train_data[class_name]\n    classifier = LogisticRegression(solver='sag')\n\n    cv_score = np.mean(cross_val_score(\n        classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n    scores.append(cv_score)\n    print('CV score for class {} is {}'.format(class_name, cv_score))\n\n    classifier.fit(train_features, train_target)\n    submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n\nprint('Total CV score is {}'.format(np.mean(scores)))\n\n# Result to csv file for submission\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[{"output_type":"stream","text":"CV score for class toxic is 0.9783631232467468\nCV score for class severe_toxic is 0.9888028544009436\nCV score for class obscene is 0.9902144263172298\nCV score for class threat is 0.9886645053037882\nCV score for class insult is 0.9828570507169597\n","name":"stdout"}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}