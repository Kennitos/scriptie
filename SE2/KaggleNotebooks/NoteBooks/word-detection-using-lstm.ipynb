{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os# keras module for building LSTM \nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Embedding, LSTM, Dense, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.callbacks import EarlyStopping\nfrom keras.models import Sequential\nimport keras.utils as ku\n\nimport pandas as pd\nimport numpy as np\nimport string, os","execution_count":21,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"directory='../input/'\nfor files in os.listdir('../input/'):\n    lines = [line.rstrip('\\n') for line in open(directory+files)]\nprint(lines[1:10])","execution_count":22,"outputs":[{"output_type":"stream","text":"['Aardonyx', 'Abdallahsaurus', 'Abelisaurus', 'Abrictosaurus', 'Abrosaurus', 'Abydosaurus', 'Acanthopholis', 'Achelousaurus', 'Acheroraptor']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(txt):\n    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n    return txt \ncorpus = [clean_text(x) for x in lines]","execution_count":23,"outputs":[{"output_type":"stream","text":"['aardonyx', 'abdallahsaurus', 'abelisaurus', 'abrictosaurus', 'abrosaurus', 'abydosaurus', 'acanthopholis', 'achelousaurus', 'acheroraptor']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer=Tokenizer(char_level=True)\ndef get_sequence_of_tokens(corpus):\n    ## tokenization\n    tokenizer.fit_on_texts(corpus)\n    total_words = len(tokenizer.word_index) + 1\n    input_sequences = []\n    for line in corpus:\n        token_list = tokenizer.texts_to_sequences([line])[0]\n        for i in range(1, len(token_list)):\n            n_gram_sequence = token_list[:i]\n            input_sequences.append(n_gram_sequence)\n    return input_sequences, total_words\ninp_sequences, total_words = get_sequence_of_tokens(corpus)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_padded_sequences(input_sequences):\n    max_sequence_len = max([len(x) for x in input_sequences])\n    input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n    \n    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n    label = ku.to_categorical(label, num_classes=total_words)\n    return predictors, label, max_sequence_len\n\npredictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)","execution_count":25,"outputs":[{"output_type":"stream","text":"[[ 0  0  0 ...  0  0  0]\n [ 0  0  0 ...  0  0  1]\n [ 0  0  0 ...  0  1  1]\n ...\n [ 0  0  0 ...  0  0  0]\n [ 0  0  0 ...  0  0 22]\n [ 0  0  0 ...  0 22  3]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(max_sequence_len, total_words):\n    input_len = max_sequence_len - 1\n    model = Sequential()\n    \n    # Add Input Embedding Layer\n    model.add(Embedding(total_words, 10, input_length=input_len))\n    \n    # Add Hidden Layer 1 - LSTM Layer\n    model.add(LSTM(100))\n    model.add(Dropout(0.1))\n    \n    # Add Output Layer\n    model.add(Dense(total_words, activation='softmax'))\n\n    model.compile(loss='categorical_crossentropy', optimizer='adam')\n    \n    return model\n\nmodel = create_model(max_sequence_len, total_words)\nmodel.summary()","execution_count":26,"outputs":[{"output_type":"stream","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_2 (Embedding)      (None, 24, 10)            270       \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 100)               44400     \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 100)               0         \n_________________________________________________________________\ndense_2 (Dense)              (None, 27)                2727      \n=================================================================\nTotal params: 47,397\nTrainable params: 47,397\nNon-trainable params: 0\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(predictors, label, epochs=50, verbose=3)","execution_count":27,"outputs":[{"output_type":"stream","text":"Epoch 1/50\nEpoch 2/50\nEpoch 3/50\nEpoch 4/50\nEpoch 5/50\nEpoch 6/50\nEpoch 7/50\nEpoch 8/50\nEpoch 9/50\nEpoch 10/50\nEpoch 11/50\nEpoch 12/50\nEpoch 13/50\nEpoch 14/50\nEpoch 15/50\nEpoch 16/50\nEpoch 17/50\nEpoch 18/50\nEpoch 19/50\nEpoch 20/50\nEpoch 21/50\nEpoch 22/50\nEpoch 23/50\nEpoch 24/50\nEpoch 25/50\nEpoch 26/50\nEpoch 27/50\nEpoch 28/50\nEpoch 29/50\nEpoch 30/50\nEpoch 31/50\nEpoch 32/50\nEpoch 33/50\nEpoch 34/50\nEpoch 35/50\nEpoch 36/50\nEpoch 37/50\nEpoch 38/50\nEpoch 39/50\nEpoch 40/50\nEpoch 41/50\nEpoch 42/50\nEpoch 43/50\nEpoch 44/50\nEpoch 45/50\nEpoch 46/50\nEpoch 47/50\nEpoch 48/50\nEpoch 49/50\nEpoch 50/50\n","name":"stdout"},{"output_type":"execute_result","execution_count":27,"data":{"text/plain":"<keras.callbacks.History at 0x7f19cfec1d30>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_text(seed_text, next_words, model, max_sequence_len):\n    for _ in range(next_words):\n        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n        predicted = model.predict_classes(token_list, verbose=2)\n        \n        output_word = \"\"\n        for word,index in tokenizer.word_index.items():\n            if index == predicted:\n                output_word = word\n                break\n        seed_text += output_word\n    return seed_text.title()","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputdata=input(\"Enter the text:\")\nprint (generate_text(inputdata, 8, model, max_sequence_len))\n","execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":"Enter the text:fus\nFusuisaurus\n"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}