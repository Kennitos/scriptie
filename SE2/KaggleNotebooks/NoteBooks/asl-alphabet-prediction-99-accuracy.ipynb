{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom fastai.vision import *\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"path = Path(\"../input/asl_alphabet_train/asl_alphabet_train\")\ncategories = os.listdir(path)\n\npaths =[]\nfor cat in categories:\n    paths.append(Path(f'{path}/{cat}'))\n    \ndef sample_plots(paths : list, categories : list):\n    _,axs = plt.subplots(6,5,figsize=(12,12))\n    \n    n = 0\n    for p in paths: \n        for i in [os.listdir(p)[0]]:\n            img = open_image(f'{p}/{i}')\n            img.show(axs[n%6][n//6], title=f'{categories[n]}')\n            n+=1\n\n    plt.tight_layout()\nsample_plots(paths, categories)\n\ndef class_balance(path, categories):\n    t = 0\n    class_n = dict()\n    for cat in categories:\n        class_n[cat] = len(os.listdir(path/cat))\n        t += class_n[cat]\n    pd.DataFrame(dict(class_n=class_n)).plot.bar()\n    return t\n\nt = class_balance(path, categories)\n\nfrom fastai.torch_core import *\ndefault_device = torch.device('cuda')\n\nid_list = []\nfor cat in categories:\n    id_list += os.listdir(path/cat)\n\nid_list = np.array(id_list)\nnp.random.shuffle(id_list)\nid_list = list(id_list)\n\ntfms = get_transforms(max_rotate=25, do_flip = True, flip_vert = False)\nval_idx = id_list[:int(len(id_list) * .22)]\n\nbs = int(t *.005)\ndata = (ImageList.from_folder(path)\n        .split_by_files(valid_names=val_idx)\n        .label_from_folder()\n        .transform(tfms,size=200)\n        .databunch(bs=bs, num_workers=5)\n        .normalize(imagenet_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(categories), data.c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.device = torch.device('cuda:0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(data, models.resnet18, wd=.01, model_dir=\"/tmp/model/\", metrics=accuracy)\nlearn.lr_find()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_one_cycle(learn, 2, slice(1e-4, 1e-1), moms=(.9, .5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_plots(paths, categories)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,y,losses = learn.get_preds(with_loss=True)\ninterp = ClassificationInterpretation(learn, preds, y, losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interp.plot_top_losses(9, figsize=(12,12), heatmap=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('state-01')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = learn.load('state-01')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}